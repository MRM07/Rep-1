{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spell Checker ",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MRM07/Rep-1/blob/master/Spell_Checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkJwG_aQojOp",
        "colab_type": "text"
      },
      "source": [
        "The technology around spell-check and autocorrect has almost outgrown the bandwidth of human error/typos and is now used everywhere: emails, word-processors, search-queries, and even while writing codes. \n",
        "\n",
        "Here, we are trying to replicate the basic tech around spell-check which is probably just naive but provides a detailed intutition around the concept and is a very important area in Natural Language Processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWhdKb3coiyg",
        "colab_type": "text"
      },
      "source": [
        "Spelling Errors are of different types, but the most common ones we come across everyday are- \n",
        "\n",
        "1. **Non-Word errors**: Typos, which are the very usual form of errors, missing a few keys, or pressing extra keys in the neighbourhood of your keyboard.\n",
        "\n",
        "2. **Word-Errors**: Unintentionally, we sometimes end up creating a real word, while we meant sth else, ex- three/there\n",
        "\n",
        "3. **Cognitive errors**: Can be account for phonetic errors, Maybe the person's grammar is not that strong, or somewhere, we used a speech-text service, and our text result came in this form.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fHbinXOfSdM",
        "colab_type": "text"
      },
      "source": [
        "For our convenice, we will be using text file containing a million words, compiled using the excerpts from Project Gutenburg, and most frequent words from Wikitinary and British National Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBUEQlaygCmm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "argmax(c ∈ candidates) P(c|w) \n",
        "\n",
        "By **Bayes Theorem**, our equation is of the form ->\n",
        "**argmax**(c ∈ candidates) P(c)* P(w|c) / P(w)\n",
        "\n",
        "Since, P(w) is constant value, we write our equation as\n",
        "**argmax**(c ∈ candidates)P(c)* P(w|c)\n",
        "\n",
        "Our equation has 4 expressions:\n",
        "  1. Choosing c which has maximum joint probability\n",
        "  2. Choosing a set of candidates c, to consider\n",
        "  3. P(c) calculated from the language model, larger the no. of data, better the      corpus is\n",
        "  4. P(w|c) Probability that w was typed, when the author meant c. \n",
        "     ex P(thew|the) >> P(thedey|the)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeayB6U_qymb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "def words(text):\n",
        "  return re.findall(r'\\w+' ,text.lower())\n",
        "\n",
        "#word_count_dictionary is a key value pair of  word-frequency\n",
        "WORD_COUNT_DICTIONARY= Counter(words(open(\"big.txt\").read()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFqPiRmtk5PH",
        "colab_type": "text"
      },
      "source": [
        "Levenshtein Distance is a measure of distance between 2 strings. Here ,the difference between the correct string and its incorrect counterpart in terms of the no. of transformations that are needed to be made.\n",
        "\n",
        "We will first work on the candidate model where we will be able to get back all transformation possible on the word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuUKAghboqKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if only 1 edit is allowed\n",
        "def edit1(word):\n",
        "  \n",
        "  split_vocab= [(word[:i], word[i:]) for i in range(len(word)+1) ]\n",
        "  letters= \"abcdefghijklmnopqrstuvwxyz\"\n",
        "  delete_op= [L + R[1:] for L, R  in split_vocab if R ]\n",
        "  transpose_op= [L +R[1] +R[0] +R[2:] for L,R in split_vocab if len(R) > 1]\n",
        "  substitution_op= [L + C + R[1:] for L, R  in split_vocab if R for C in letters  ]\n",
        "  insert_op = [L + C + R for L, R  in split_vocab for C in letters]\n",
        "  return set(insert_op + delete_op + transpose_op + substitution_op)\n",
        "\n",
        "#if  2 edits are allowed\n",
        "def edit2(word):\n",
        "  return ( e2 for e1 in edit1(word) for e2 in edit1(e1) )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rstsiz7Rv2fl",
        "colab_type": "text"
      },
      "source": [
        "We have to also filter out our transformed dataset by only including the words which are present in our actual language model. Let's write a function for that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA5CumLowJx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filtered(words):\n",
        "  return set(w for w in words if w in WORD_COUNT_DICTIONARY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUKJkILmwWaG",
        "colab_type": "text"
      },
      "source": [
        "Now, let's work on generating possible spell corrections for our incorrectly spelt words. Basically, write a function which combines the above 2 blocks of function and returns us a candidate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrRVZburwuqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def candidate_model_vocabulary(word):\n",
        "  return (filtered([word]) or filtered(edit1(word)) or filtered(edit2(word)) or [word] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjo80Gh4x0hO",
        "colab_type": "text"
      },
      "source": [
        "Let's write a function which tells us the probability of a word in the language model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul8AoIwnyAF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Probablity_Scores(word, N=sum(WORD_COUNT_DICTIONARY.values())): \n",
        "    \"Probability of `word`.\"\n",
        "    return WORD_COUNT_DICTIONARY[word] / N"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4SOFjR0yKmL",
        "colab_type": "text"
      },
      "source": [
        "Let's create a function which is going to return us the correct spelling of our incorrectly spelt word based on the probability values of the candidate list of probable words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyrvN2vbyYuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correction(word):\n",
        "  \"Most probable spelling correction\"\n",
        "  return max(candidate_model_vocabulary(word), key= Probablity_Scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa61Rv1hzpPt",
        "colab_type": "text"
      },
      "source": [
        "We have built our function. Let's test our code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE40rKIwzngx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c9fd3053-8ed8-495e-917f-e0b6de3a309f"
      },
      "source": [
        "print(correction('speling'))\n",
        "print(correction('korrectiun'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spelling\n",
            "correction\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}